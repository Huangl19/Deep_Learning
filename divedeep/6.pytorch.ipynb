{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a4c88a",
   "metadata": {},
   "source": [
    "# 6.Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bd58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b35350",
   "metadata": {},
   "source": [
    "## 1. 层绑定参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55509f17",
   "metadata": {},
   "source": [
    "nn.Sequential 类可以直接使用切片找到对应的层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735a6e7",
   "metadata": {},
   "source": [
    "如果在 nn.module 的类中没有使用self. 变量绑定模型，则无法将子层的参数用优化器优化，下方代码中的list 需要修改为 nn.Sequential 类。\n",
    "\n",
    "```python\n",
    "class MySequential(d2l.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.modules = []\n",
    "        for idx, module in enumerate(args):\n",
    "            self.modules.append(module)\n",
    "            \n",
    "    def forward(self, X):\n",
    "        for module in self.modules:\n",
    "            X = module(X)\n",
    "        return X\n",
    "    \n",
    "ValueError: optimizer got an empty parameter list  # 报错\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8867fcf",
   "metadata": {},
   "source": [
    "上述错误需要将模型挂在 self._modules下 , 该属性会初始化为有序字典（.state_dict()方法返回的就是该属性）。  \n",
    "其中 key 与 value 均为 nn 的层，有序字典则模型层的顺序与传入的顺序相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13790fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for block in args:\n",
    "            self._modules[block] = block\n",
    "            \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "net = test(nn.Linear(2,2), nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5595166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.linear.Linear"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(net._modules.keys())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4d9f3e",
   "metadata": {},
   "source": [
    "## 2. 共享模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f6ed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.virtualenvs/basenv/lib/python3.7/site-packages/torch/nn/modules/lazy.py:175: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "shared = nn.LazyLinear(8)\n",
    "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    nn.LazyLinear(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b575e",
   "metadata": {},
   "source": [
    "由于模型参数包含梯度，因此在反向传播过程中，第二个共享隐藏层和第三个共享隐藏层的梯度会加在一起。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcfabdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  add_module 方法可以为模型添加具有名字的模块\n",
    "net.add_module('test1', nn.Linear(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f50df3",
   "metadata": {},
   "source": [
    "## 3. 参数初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a429bba",
   "metadata": {},
   "source": [
    "自定义初始化参数，使用apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5dcda2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.LazyLinear(8), nn.ReLU(), nn.LazyLinear(1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f30df1",
   "metadata": {},
   "source": [
    "注意使用带后缀_的函数， 这种类型表示替换而不是返回值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8028886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-9.4872,  0.0000, -0.0000, -0.0000],\n",
       "        [-9.8747,  0.0000,  7.0784,  7.5458]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape)\n",
    "                        for name, param in module.named_parameters()][0])\n",
    "        nn.init.uniform_(module.weight, -10, 10)\n",
    "        module.weight.data *= module.weight.data.abs() >= 5\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044b8f5e",
   "metadata": {},
   "source": [
    "## 4. 自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c2b0af",
   "metadata": {},
   "source": [
    "自定义层中需要在 self 中绑定相应的权重（参数类型）， 使用该类型的 data 进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data  # 使用参数的 data 数据计算结果\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9f672",
   "metadata": {},
   "source": [
    "## 5. GPU device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c5825",
   "metadata": {},
   "source": [
    "在变量定义的时候直接指定device， 可以减少 to(device) 的时间，to 实际是在设备间 copy 数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba17c4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://cdn.jsdelivr.net/gh/Huangl19/imgbed/202407301009797.png\" width='1000px' >\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95126d30",
   "metadata": {},
   "source": [
    "如果不小心移动数据，可能会严重影响性能。  \n",
    "一个典型的错误如下：在 GPU 上计算每个小批量的损失并在命令行上将其报告给用户（或将其记录在 NumPy 中ndarray）将触发全局解释器锁，从而使所有 GPU 停止运行。  \n",
    "最好在 GPU 内部分配用于记录的内存并只移动较大的日志。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81cc7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.ones(2, 3, device='cpu')  # 在定义变量的时候就指定设备"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
